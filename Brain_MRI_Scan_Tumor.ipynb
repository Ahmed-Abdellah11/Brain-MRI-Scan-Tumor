{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:11.920779Z",
          "iopub.execute_input": "2023-12-30T21:42:11.921048Z",
          "iopub.status.idle": "2023-12-30T21:42:25.827124Z",
          "shell.execute_reply.started": "2023-12-30T21:42:11.921023Z",
          "shell.execute_reply": "2023-12-30T21:42:25.825969Z"
        },
        "trusted": true,
        "id": "QTN_4ODNUMwX",
        "outputId": "30272854-8351-4110-c71a-923ca1ad4289"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.0.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n",
          "output_type": "stream"
        }
      ],
      "id": "QTN_4ODNUMwX"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms import ToTensor, Lambda\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:25.829546Z",
          "iopub.execute_input": "2023-12-30T21:42:25.830336Z",
          "iopub.status.idle": "2023-12-30T21:42:29.720425Z",
          "shell.execute_reply.started": "2023-12-30T21:42:25.830298Z",
          "shell.execute_reply": "2023-12-30T21:42:29.719582Z"
        },
        "trusted": true,
        "id": "1w0j5bGUUMwc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1w0j5bGUUMwc"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:29.721760Z",
          "iopub.execute_input": "2023-12-30T21:42:29.722143Z",
          "iopub.status.idle": "2023-12-30T21:42:29.792743Z",
          "shell.execute_reply.started": "2023-12-30T21:42:29.722116Z",
          "shell.execute_reply": "2023-12-30T21:42:29.791721Z"
        },
        "trusted": true,
        "id": "K_fxTgNjUMwg"
      },
      "execution_count": null,
      "outputs": [],
      "id": "K_fxTgNjUMwg"
    },
    {
      "cell_type": "code",
      "source": [
        "class MirroredStrategy:\n",
        "    def __init__(self, devices):\n",
        "        self.devices = devices\n",
        "        self.device_count = len(devices)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        pass\n",
        "\n",
        "    def scope(self):\n",
        "        return torch.cuda.device(self.devices[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:29.795009Z",
          "iopub.execute_input": "2023-12-30T21:42:29.795334Z",
          "iopub.status.idle": "2023-12-30T21:42:29.802711Z",
          "shell.execute_reply.started": "2023-12-30T21:42:29.795307Z",
          "shell.execute_reply": "2023-12-30T21:42:29.801772Z"
        },
        "trusted": true,
        "id": "HgNOpvyPUMwg"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HgNOpvyPUMwg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the TensorFlow code with PyTorch\n",
        "mirrored_strategy = MirroredStrategy(devices=[\"cuda:4\", \"cuda:5\", \"cuda:6\", \"cuda:7\"])\n",
        "\n",
        "tar_path = '/kaggle/input/brain-t1-and-t1c-scans/T1c Cropped 3D-T/T1c_imgs_middle_only/'\n",
        "src_path = '/kaggle/input/brain-t1-and-t1c-scans/T1 Cropped 3D-T/T1_imgs_middle_only/'\n",
        "img_size = (145, 184)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:29.803901Z",
          "iopub.execute_input": "2023-12-30T21:42:29.804258Z",
          "iopub.status.idle": "2023-12-30T21:42:29.812318Z",
          "shell.execute_reply.started": "2023-12-30T21:42:29.804233Z",
          "shell.execute_reply": "2023-12-30T21:42:29.811495Z"
        },
        "trusted": true,
        "id": "Z7-f_TPsUMwh"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Z7-f_TPsUMwh"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DownsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, apply_batchnorm=True):\n",
        "        super(DownsampleBlock, self).__init__()\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(out_channels) if apply_batchnorm else nn.Identity(),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        ]\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, apply_dropout=False):\n",
        "        super(UpsampleBlock, self).__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        if apply_dropout:\n",
        "            layers.append(nn.Dropout(0.5))\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.down_stack = nn.ModuleList([\n",
        "            DownsampleBlock(3, 64, False),\n",
        "            DownsampleBlock(64, 128),\n",
        "            DownsampleBlock(128, 256),\n",
        "            DownsampleBlock(256, 512),\n",
        "            DownsampleBlock(512, 512),\n",
        "            DownsampleBlock(512, 512),\n",
        "            DownsampleBlock(512, 512),\n",
        "            DownsampleBlock(512, 512)\n",
        "        ])\n",
        "\n",
        "        self.up_stack = nn.ModuleList([\n",
        "            UpsampleBlock(512, 512, True),\n",
        "            UpsampleBlock(1024, 512, True),\n",
        "            UpsampleBlock(1024, 512, True),\n",
        "            UpsampleBlock(1024, 512),\n",
        "            UpsampleBlock(512, 256),\n",
        "            UpsampleBlock(256, 128),\n",
        "            UpsampleBlock(128, 64),\n",
        "        ])\n",
        "\n",
        "        self.last = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for down in self.down_stack:\n",
        "            x = down(x)\n",
        "            skips.append(x)\n",
        "        skips = reversed(skips[:-1])\n",
        "\n",
        "        for up, skip in zip(self.up_stack, skips):\n",
        "            x = up(x)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "\n",
        "        x = self.last(x)\n",
        "        return torch.tanh(x)\n",
        "\n",
        "# Example usage:\n",
        "gen = Generator()\n",
        "print(gen)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:29.813505Z",
          "iopub.execute_input": "2023-12-30T21:42:29.813839Z",
          "iopub.status.idle": "2023-12-30T21:42:30.288604Z",
          "shell.execute_reply.started": "2023-12-30T21:42:29.813807Z",
          "shell.execute_reply": "2023-12-30T21:42:30.287671Z"
        },
        "trusted": true,
        "id": "zrZfl-BHUMwi",
        "outputId": "07fa81ff-0c9d-41f3-9306-4f29936004e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generator(\n  (down_stack): ModuleList(\n    (0): DownsampleBlock(\n      (block): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): Identity()\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (1): DownsampleBlock(\n      (block): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (2): DownsampleBlock(\n      (block): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (3): DownsampleBlock(\n      (block): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n    (4-7): 4 x DownsampleBlock(\n      (block): Sequential(\n        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n      )\n    )\n  )\n  (up_stack): ModuleList(\n    (0): UpsampleBlock(\n      (block): Sequential(\n        (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): ReLU(inplace=True)\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (1-2): 2 x UpsampleBlock(\n      (block): Sequential(\n        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): ReLU(inplace=True)\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (3): UpsampleBlock(\n      (block): Sequential(\n        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): ReLU(inplace=True)\n      )\n    )\n    (4): UpsampleBlock(\n      (block): Sequential(\n        (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): ReLU(inplace=True)\n      )\n    )\n    (5): UpsampleBlock(\n      (block): Sequential(\n        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): ReLU(inplace=True)\n      )\n    )\n    (6): UpsampleBlock(\n      (block): Sequential(\n        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n        (2): ReLU(inplace=True)\n      )\n    )\n  )\n  (last): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n)\n",
          "output_type": "stream"
        }
      ],
      "id": "zrZfl-BHUMwi"
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator().to(device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:30.289706Z",
          "iopub.execute_input": "2023-12-30T21:42:30.289977Z",
          "iopub.status.idle": "2023-12-30T21:42:34.002983Z",
          "shell.execute_reply.started": "2023-12-30T21:42:30.289952Z",
          "shell.execute_reply": "2023-12-30T21:42:34.002169Z"
        },
        "trusted": true,
        "id": "vG02SNsmUMwk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vG02SNsmUMwk"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.down1 = DownsampleBlock(6, 64, False)\n",
        "        self.down2 = DownsampleBlock(64, 128)\n",
        "        self.down3 = DownsampleBlock(128, 256)\n",
        "\n",
        "        self.zero_pad1 = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.conv = nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.zero_pad2 = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "\n",
        "        self.last = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        x = torch.cat([input, target], dim=1)\n",
        "\n",
        "        x = self.down1(x)\n",
        "        x = self.down2(x)\n",
        "        x = self.down3(x)\n",
        "\n",
        "        x = self.zero_pad1(x)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.zero_pad2(x)\n",
        "\n",
        "        x = self.last(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "discriminator = Discriminator()\n",
        "print(discriminator)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:34.004144Z",
          "iopub.execute_input": "2023-12-30T21:42:34.004430Z",
          "iopub.status.idle": "2023-12-30T21:42:34.042747Z",
          "shell.execute_reply.started": "2023-12-30T21:42:34.004404Z",
          "shell.execute_reply": "2023-12-30T21:42:34.041839Z"
        },
        "trusted": true,
        "id": "9ojawpKnUMwl",
        "outputId": "5162f9a0-70c0-445f-8a21-bb3715a1b953"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Discriminator(\n  (down1): DownsampleBlock(\n    (block): Sequential(\n      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (1): Identity()\n      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n    )\n  )\n  (down2): DownsampleBlock(\n    (block): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n    )\n  )\n  (down3): DownsampleBlock(\n    (block): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n    )\n  )\n  (zero_pad1): ZeroPad2d((1, 0, 1, 0))\n  (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n  (leaky_relu): LeakyReLU(negative_slope=0.2, inplace=True)\n  (zero_pad2): ZeroPad2d((1, 0, 1, 0))\n  (last): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n)\n",
          "output_type": "stream"
        }
      ],
      "id": "9ojawpKnUMwl"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import L1Loss\n",
        "\n",
        "def generator_loss(disc_generated_output, gen_output, target, lambda_value):\n",
        "    mae = L1Loss()\n",
        "\n",
        "    gan_loss = F.binary_cross_entropy_with_logits(disc_generated_output, torch.ones_like(disc_generated_output))\n",
        "    l1_loss = mae(gen_output, target)\n",
        "    total_gen_loss = gan_loss + (lambda_value * l1_loss)\n",
        "\n",
        "    return total_gen_loss, gan_loss, l1_loss\n",
        "\n",
        "\n",
        "\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    mae = L1Loss()\n",
        "\n",
        "    real_loss = mae(torch.ones_like(disc_real_output), disc_real_output)\n",
        "    generated_loss = mae(torch.zeros_like(disc_generated_output), disc_generated_output)\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss\n",
        "\n",
        "\n",
        "generator_optimizer = optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:34.043910Z",
          "iopub.execute_input": "2023-12-30T21:42:34.044261Z",
          "iopub.status.idle": "2023-12-30T21:42:34.053488Z",
          "shell.execute_reply.started": "2023-12-30T21:42:34.044227Z",
          "shell.execute_reply": "2023-12-30T21:42:34.052395Z"
        },
        "trusted": true,
        "id": "g4i-hSBUUMwn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "g4i-hSBUUMwn"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(input_image, target, epoch):\n",
        "    gen.train()\n",
        "    disc.train()\n",
        "\n",
        "    # Move data to device (if using GPU)\n",
        "    input_image, target = input_image.to(device), target.to(device)\n",
        "\n",
        "    # Generator forward pass\n",
        "    gen_output = gen(input_image)\n",
        "\n",
        "    # Discriminator forward pass\n",
        "    disc_real_output = disc(torch.cat([input_image, target], dim=1))\n",
        "    disc_generated_output = disc(torch.cat([input_image, gen_output.detach()], dim=1))\n",
        "\n",
        "    # Compute losses\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target, LAMBDA)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    # Generator backward pass and optimization\n",
        "    generator_optimizer.zero_grad()\n",
        "    gen_total_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    # Discriminator backward pass and optimization\n",
        "    discriminator_optimizer.zero_grad()\n",
        "    disc_loss.backward()\n",
        "    discriminator_optimizer.step()\n",
        "\n",
        "    return gen_total_loss.item(), disc_loss.item()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:34.056965Z",
          "iopub.execute_input": "2023-12-30T21:42:34.057242Z",
          "iopub.status.idle": "2023-12-30T21:42:34.065126Z",
          "shell.execute_reply.started": "2023-12-30T21:42:34.057218Z",
          "shell.execute_reply": "2023-12-30T21:42:34.064298Z"
        },
        "trusted": true,
        "id": "Fu8U5KN0UMwo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Fu8U5KN0UMwo"
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(train_loader, test_loader, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        directory = 'output'\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "        for input_, target in test_loader:\n",
        "            save_images(gen, input_, target, epoch)\n",
        "\n",
        "        # Train\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        for n, (input_, target) in enumerate(train_loader):\n",
        "            input_ = input_.to(device)\n",
        "            target = target.to(device)\n",
        "            gen_loss, disc_loss = train_step(input_, target, epoch)\n",
        "\n",
        "        gen_loss_value = gen_loss.item()\n",
        "        disc_loss_value = disc_loss.item()\n",
        "\n",
        "        gen_losses.append(gen_loss_value)\n",
        "        disc_losses.append(disc_loss_value)\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            torch.save({\n",
        "                'generator_state_dict': gen.state_dict(),\n",
        "                'discriminator_state_dict': disc.state_dict(),\n",
        "                'gen_optimizer_state_dict': generator_optimizer.state_dict(),\n",
        "                'disc_optimizer_state_dict': discriminator_optimizer.state_dict(),\n",
        "            }, f'checkpoint_epoch_{epoch}.pt')\n",
        "\n",
        "        print(\"Generator loss: {:.2f}\".format(gen_loss_value))\n",
        "        print(\"Discriminator loss: {:.2f}\".format(disc_loss_value))\n",
        "        print(\"Time taken for epoch {} is {} sec\\n\".format(epoch+1, time.time() - start))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:34.066202Z",
          "iopub.execute_input": "2023-12-30T21:42:34.066553Z",
          "iopub.status.idle": "2023-12-30T21:42:34.078344Z",
          "shell.execute_reply.started": "2023-12-30T21:42:34.066518Z",
          "shell.execute_reply": "2023-12-30T21:42:34.077469Z"
        },
        "trusted": true,
        "id": "_o9TjbohUMwo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_o9TjbohUMwo"
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(img):\n",
        "    img = (img / 127.5) - 1\n",
        "    return img\n",
        "\n",
        "def resize(img):\n",
        "    # Use torchvision.transforms.Resize for resizing\n",
        "    transform = nn.Upsample(size=(256, 256), mode='nearest')\n",
        "    img = transform(img)\n",
        "    return img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:34.079562Z",
          "iopub.execute_input": "2023-12-30T21:42:34.079838Z",
          "iopub.status.idle": "2023-12-30T21:42:34.089599Z",
          "shell.execute_reply.started": "2023-12-30T21:42:34.079813Z",
          "shell.execute_reply": "2023-12-30T21:42:34.088753Z"
        },
        "trusted": true,
        "id": "tYrOV8eSUMwp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "tYrOV8eSUMwp"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install natsort\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:34.090559Z",
          "iopub.execute_input": "2023-12-30T21:42:34.090790Z",
          "iopub.status.idle": "2023-12-30T21:42:46.460398Z",
          "shell.execute_reply.started": "2023-12-30T21:42:34.090769Z",
          "shell.execute_reply": "2023-12-30T21:42:46.459079Z"
        },
        "trusted": true,
        "id": "XCnGcjjmUMwr",
        "outputId": "ba310bdd-50d4-4abf-b260-eabbaa6f6e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting natsort\n  Obtaining dependency information for natsort from https://files.pythonhosted.org/packages/ef/82/7a9d0550484a62c6da82858ee9419f3dd1ccc9aa1c26a1e43da3ecd20b0d/natsort-8.4.0-py3-none-any.whl.metadata\n  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\nDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\nInstalling collected packages: natsort\nSuccessfully installed natsort-8.4.0\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "id": "XCnGcjjmUMwr"
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path, listdir\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.461910Z",
          "iopub.execute_input": "2023-12-30T21:42:46.462210Z",
          "iopub.status.idle": "2023-12-30T21:42:46.467455Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.462181Z",
          "shell.execute_reply": "2023-12-30T21:42:46.466331Z"
        },
        "trusted": true,
        "id": "GgV0u41qUMws"
      },
      "execution_count": null,
      "outputs": [],
      "id": "GgV0u41qUMws"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VfwdBzi0UMws"
      },
      "execution_count": null,
      "outputs": [],
      "id": "VfwdBzi0UMws"
    },
    {
      "cell_type": "code",
      "source": [
        "src_list = []\n",
        "tar_list = []\n",
        "\n",
        "for filename in all_files:\n",
        "    img = plt.imread(src_path + filename)\n",
        "    img = normalize(img)\n",
        "    img = resize(img)\n",
        "    src_list.append(img)\n",
        "\n",
        "for filename in all_files:\n",
        "\n",
        "    img = plt.imread(tar_path + filename)\n",
        "    img = normalize(img)\n",
        "    img = resize(img)\n",
        "    tar_list.append(img)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.468806Z",
          "iopub.execute_input": "2023-12-30T21:42:46.469142Z",
          "iopub.status.idle": "2023-12-30T21:42:46.939535Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.469115Z",
          "shell.execute_reply": "2023-12-30T21:42:46.938355Z"
        },
        "trusted": true,
        "id": "1BcTr5KQUMws",
        "outputId": "0af90fb1-30cb-45a6-bbf4-b5ec40390f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m src_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m tar_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_files\u001b[49m:\n\u001b[1;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(src_path \u001b[38;5;241m+\u001b[39m filename)\n\u001b[1;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m normalize(img)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_files' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'all_files' is not defined",
          "output_type": "error"
        }
      ],
      "id": "1BcTr5KQUMws"
    },
    {
      "cell_type": "code",
      "source": [
        "src_list = torch.stack(src_list).to(device)\n",
        "tar_list = torch.stack(tar_list).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.940641Z",
          "iopub.status.idle": "2023-12-30T21:42:46.941006Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.940831Z",
          "shell.execute_reply": "2023-12-30T21:42:46.940847Z"
        },
        "trusted": true,
        "id": "0DS_sVdlUMwt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0DS_sVdlUMwt"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(src_list, tar_list)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.942358Z",
          "iopub.status.idle": "2023-12-30T21:42:46.942952Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.942778Z",
          "shell.execute_reply": "2023-12-30T21:42:46.942795Z"
        },
        "trusted": true,
        "id": "E9M-BsdcUMwu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "E9M-BsdcUMwu"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gen.state_dict(), 'generator55.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.944345Z",
          "iopub.status.idle": "2023-12-30T21:42:46.944703Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.944539Z",
          "shell.execute_reply": "2023-12-30T21:42:46.944556Z"
        },
        "trusted": true,
        "id": "nsSLbFKZUMwu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nsSLbFKZUMwu"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(inputs)):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    display_list = [inputs[i][0], targets[i][0], predictions[i][0]]\n",
        "\n",
        "    # Structural similarity calculation for PyTorch tensors\n",
        "    target_np = (targets[i][0].cpu().numpy() + 1) / 2.0\n",
        "    prediction_np = (predictions[i][0].cpu().numpy() + 1) / 2.0\n",
        "    score, diff = structural_similarity(target_np, prediction_np, full=True, win_size=3, data_range=2)\n",
        "    score = f'{score:.3f}'\n",
        "    titles = ['Input Image', 'Ground Truth', f'Predicted Image: {score}']\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(titles[i])\n",
        "        plt.imshow(display_list[i].cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "        plt.axis('off')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.946192Z",
          "iopub.status.idle": "2023-12-30T21:42:46.946530Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.946345Z",
          "shell.execute_reply": "2023-12-30T21:42:46.946359Z"
        },
        "trusted": true,
        "id": "MzSWIiROUMwu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MzSWIiROUMwu"
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_dict = torch.load('checkpoint_epoch_10.pth')\n",
        "gen.load_state_dict(loaded_dict['generator_state_dict'])\n",
        "disc.load_state_dict(loaded_dict['discriminator_state_dict'])\n",
        "generator_optimizer.load_state_dict(loaded_dict['gen_optimizer_state_dict'])\n",
        "discriminator_optimizer.load_state_dict(loaded_dict['disc_optimizer_state_dict'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.947412Z",
          "iopub.status.idle": "2023-12-30T21:42:46.947780Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.947616Z",
          "shell.execute_reply": "2023-12-30T21:42:46.947632Z"
        },
        "trusted": true,
        "id": "Yjzdx7WPUMwv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Yjzdx7WPUMwv"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(gen_losses, label='gen_loss')\n",
        "plt.plot(disc_losses, label='disc_loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-30T21:42:46.948825Z",
          "iopub.status.idle": "2023-12-30T21:42:46.949123Z",
          "shell.execute_reply.started": "2023-12-30T21:42:46.948971Z",
          "shell.execute_reply": "2023-12-30T21:42:46.948985Z"
        },
        "trusted": true,
        "id": "Z8uUGaQwUMww"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Z8uUGaQwUMww"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hk8z2X5UMww"
      },
      "execution_count": null,
      "outputs": [],
      "id": "2hk8z2X5UMww"
    }
  ]
}